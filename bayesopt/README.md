# Bayesian Optimization for Hyperparameter Tuning in Machine Learning

Authors: Jakob Richter

### Description

In this workshop you will learn how to use Bayesian optimization (also known as Model-based optimization) to tune the performance of your machine learning model.
We will cover basic aspects of hyperparameter tuning such as nested resampling as well as the theoretical foundations of Bayesian optimization.
This tutorial will also cover basic concepts of parallelization and handling of complex search spaces within the Bayesian optimization framework.
The examples in this workshop will use the R-packages `mlr3`, `mlr3tuning` and `mlr3mbo`.
Note, that `mlr3mbo` is currently under development and the concrete code examples in this workshop will likely change in the future after the workshop. 


## Requirements

* basic knowledge of R and machine learning
* installed RStudio and packages `mlr3`, `mlr3tuning`, `mlr3learners`.